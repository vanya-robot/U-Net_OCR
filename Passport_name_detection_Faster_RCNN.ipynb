{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2be15b9a68ba4b2d977f95f5cd42f5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6613be69f0a9416cbe0dcc59121e0d7f",
              "IPY_MODEL_aacb071289a64412ab17b19acd7b23e3",
              "IPY_MODEL_2aeeca2393e14e50b991d76380e60411"
            ],
            "layout": "IPY_MODEL_ec949a8b77dc47f8bcdba8c0131e3c37"
          }
        },
        "6613be69f0a9416cbe0dcc59121e0d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bb186e30884be8831d8f0f50616817",
            "placeholder": "​",
            "style": "IPY_MODEL_71e3cebd78614b4fa90e0bd7d17c29bb",
            "value": "100%"
          }
        },
        "aacb071289a64412ab17b19acd7b23e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b20310f501454b569f7f705173ac4f20",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f6a65c460594d69998c6367972eeb5d",
            "value": 167502836
          }
        },
        "2aeeca2393e14e50b991d76380e60411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b8bbf2668d41a6850fedc4ccb3c966",
            "placeholder": "​",
            "style": "IPY_MODEL_5242d2de5ce5430aba62c816ee9b7976",
            "value": " 160M/160M [00:02&lt;00:00, 84.7MB/s]"
          }
        },
        "ec949a8b77dc47f8bcdba8c0131e3c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bb186e30884be8831d8f0f50616817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e3cebd78614b4fa90e0bd7d17c29bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b20310f501454b569f7f705173ac4f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6a65c460594d69998c6367972eeb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06b8bbf2668d41a6850fedc4ccb3c966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5242d2de5ce5430aba62c816ee9b7976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VJ-Wi6y-hqWP"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torch\n",
        "import torch.utils\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader\n",
        ")\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import math\n",
        "import sys\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import engine\n",
        "import train\n",
        "#import detection.detectionutils  # Get this folder into the project directory from https://github.com/pytorch/vision/tree/main/references/detection\n",
        "#import detection.engine  # In order to work in Colab, you need to change rows 7-9 of engine.py to:\n",
        "                                                                  # import detection.utils\n",
        "                                                                  # from detection.coco_eval import CocoEvaluator\n",
        "                                                                  # from detection.coco_utils import get_coco_api_from_dataset\n",
        "                                                                  # Also in coco_utils.py you need to change 7th row to 'import torchvision.transforms as T'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import errno\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "\n",
        "class SmoothedValue:\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        if not is_dist_avail_and_initialized():\n",
        "            return\n",
        "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device=\"cuda\")\n",
        "        dist.barrier()\n",
        "        dist.all_reduce(t)\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median, avg=self.avg, global_avg=self.global_avg, max=self.max, value=self.value\n",
        "        )\n",
        "\n",
        "\n",
        "def all_gather(data):\n",
        "    \"\"\"\n",
        "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
        "    Args:\n",
        "        data: any picklable object\n",
        "    Returns:\n",
        "        list[data]: list of data gathered from each rank\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size == 1:\n",
        "        return [data]\n",
        "    data_list = [None] * world_size\n",
        "    dist.all_gather_object(data_list, data)\n",
        "    return data_list\n",
        "\n",
        "\n",
        "def reduce_dict(input_dict, average=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dict (dict): all the values will be reduced\n",
        "        average (bool): whether to do average or sum\n",
        "    Reduce the values in the dictionary from all processes so that all processes\n",
        "    have the averaged results. Returns a dict with the same fields as\n",
        "    input_dict, after reduction.\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size < 2:\n",
        "        return input_dict\n",
        "    with torch.inference_mode():\n",
        "        names = []\n",
        "        values = []\n",
        "        # sort the keys so that they are consistent across processes\n",
        "        for k in sorted(input_dict.keys()):\n",
        "            names.append(k)\n",
        "            values.append(input_dict[k])\n",
        "        values = torch.stack(values, dim=0)\n",
        "        dist.all_reduce(values)\n",
        "        if average:\n",
        "            values /= world_size\n",
        "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
        "    return reduced_dict\n",
        "\n",
        "\n",
        "class MetricLogger:\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(f\"{name}: {str(meter)}\")\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = \"\"\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        data_time = SmoothedValue(fmt=\"{avg:.4f}\")\n",
        "        space_fmt = \":\" + str(len(str(len(iterable)))) + \"d\"\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg = self.delimiter.join(\n",
        "                [\n",
        "                    header,\n",
        "                    \"[{0\" + space_fmt + \"}/{1}]\",\n",
        "                    \"eta: {eta}\",\n",
        "                    \"{meters}\",\n",
        "                    \"time: {time}\",\n",
        "                    \"data: {data}\",\n",
        "                    \"max mem: {memory:.0f}\",\n",
        "                ]\n",
        "            )\n",
        "        else:\n",
        "            log_msg = self.delimiter.join(\n",
        "                [header, \"[{0\" + space_fmt + \"}/{1}]\", \"eta: {eta}\", \"{meters}\", \"time: {time}\", \"data: {data}\"]\n",
        "            )\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i,\n",
        "                            len(iterable),\n",
        "                            eta=eta_string,\n",
        "                            meters=str(self),\n",
        "                            time=str(iter_time),\n",
        "                            data=str(data_time),\n",
        "                            memory=torch.cuda.max_memory_allocated() / MB,\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    print(\n",
        "                        log_msg.format(\n",
        "                            i, len(iterable), eta=eta_string, meters=str(self), time=str(iter_time), data=str(data_time)\n",
        "                        )\n",
        "                    )\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print(f\"{header} Total time: {total_time_str} ({total_time / len(iterable):.4f} s / it)\")\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST:\n",
        "            raise\n",
        "\n",
        "\n",
        "def setup_for_distributed(is_master):\n",
        "    \"\"\"\n",
        "    This function disables printing when not in master process\n",
        "    \"\"\"\n",
        "    import builtins as __builtin__\n",
        "\n",
        "    builtin_print = __builtin__.print\n",
        "\n",
        "    def print(*args, **kwargs):\n",
        "        force = kwargs.pop(\"force\", False)\n",
        "        if is_master or force:\n",
        "            builtin_print(*args, **kwargs)\n",
        "\n",
        "    __builtin__.print = print\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_world_size():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def get_rank():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 0\n",
        "    return dist.get_rank()\n",
        "\n",
        "\n",
        "def is_main_process():\n",
        "    return get_rank() == 0\n",
        "\n",
        "\n",
        "def save_on_master(*args, **kwargs):\n",
        "    if is_main_process():\n",
        "        torch.save(*args, **kwargs)\n",
        "\n",
        "\n",
        "def init_distributed_mode(args):\n",
        "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
        "        args.rank = int(os.environ[\"RANK\"])\n",
        "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "        args.gpu = int(os.environ[\"LOCAL_RANK\"])\n",
        "    elif \"SLURM_PROCID\" in os.environ:\n",
        "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
        "        args.gpu = args.rank % torch.cuda.device_count()\n",
        "    else:\n",
        "        print(\"Not using distributed mode\")\n",
        "        args.distributed = False\n",
        "        return\n",
        "\n",
        "    args.distributed = True\n",
        "\n",
        "    torch.cuda.set_device(args.gpu)\n",
        "    args.dist_backend = \"nccl\"\n",
        "    print(f\"| distributed init (rank {args.rank}): {args.dist_url}\", flush=True)\n",
        "    torch.distributed.init_process_group(\n",
        "        backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank\n",
        "    )\n",
        "    torch.distributed.barrier()\n",
        "    setup_for_distributed(args.rank == 0)\n"
      ],
      "metadata": {
        "id": "v9BdkZS7ZY7g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining function, which will return pretrained model with a replaced head"
      ],
      "metadata": {
        "id": "QJGAumC2EkM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_detection(num_classes):\n",
        "    # load an instance segmentation model pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    \n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "HY0DBvid1Ai3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining transforms for train and test sets"
      ],
      "metadata": {
        "id": "aB6RBAIdEw-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = FasterRCNN_ResNet50_FPN_Weights.COCO_V1.transforms\n",
        "test_transform = FasterRCNN_ResNet50_FPN_Weights.COCO_V1.transforms"
      ],
      "metadata": {
        "id": "tjwDl3PKgyYU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(train):\n",
        "    transform = []\n",
        "    transform.append(transforms.PILToTensor())\n",
        "    transform.append(transforms.ConvertImageDtype(torch.float))\n",
        "    if train:\n",
        "        transform.append(transforms.RandomHorizontalFlip(0.5))\n",
        "    return transforms.Compose(transform)"
      ],
      "metadata": {
        "id": "ntCfQO1_4BC7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Dataset class "
      ],
      "metadata": {
        "id": "7lWZ18fOFgT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MasksDataset(Dataset):\n",
        "  def __init__(self, root_dir, transform = None):\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "    self.images = list(sorted(os.listdir(os.path.join(self.root_dir, \"images\"))))\n",
        "    self.annotations = list(sorted(os.listdir(os.path.join(self.root_dir, \"annotations\"))))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = os.path.join(self.root_dir, \"images\", self.images[index])\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    annotation_path = os.path.join(self.root_dir, \"annotations\", self.annotations[index])\n",
        "    tree = ET.parse(annotation_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "\n",
        "    box = []\n",
        "    label = [1,]\n",
        "    for j in range(4):\n",
        "        box.append(int(root[5][4][j].text))\n",
        "\n",
        "    box = torch.as_tensor([box,], dtype=torch.float32)\n",
        "    label = torch.as_tensor(label, dtype=torch.int64)\n",
        "\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)  \n",
        "    target = {'boxes': box, 'labels': label}\n",
        "    return img, target\n",
        "\n"
      ],
      "metadata": {
        "id": "HEsCdVotIIij"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = r\"/content/drive/MyDrive/passport_dataset\"\n",
        "\n",
        "train_set = MasksDataset(root_dir= dataset_path, transform=get_transform(train=True))\n",
        "test_set = MasksDataset(root_dir= dataset_path, transform=get_transform(train=False))"
      ],
      "metadata": {
        "id": "Wak4QdbOFfl-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model_detection(2)"
      ],
      "metadata": {
        "id": "QRDOJmK6v6JN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "2be15b9a68ba4b2d977f95f5cd42f5ed",
            "6613be69f0a9416cbe0dcc59121e0d7f",
            "aacb071289a64412ab17b19acd7b23e3",
            "2aeeca2393e14e50b991d76380e60411",
            "ec949a8b77dc47f8bcdba8c0131e3c37",
            "e0bb186e30884be8831d8f0f50616817",
            "71e3cebd78614b4fa90e0bd7d17c29bb",
            "b20310f501454b569f7f705173ac4f20",
            "6f6a65c460594d69998c6367972eeb5d",
            "06b8bbf2668d41a6850fedc4ccb3c966",
            "5242d2de5ce5430aba62c816ee9b7976"
          ]
        },
        "outputId": "222f6a38-2561-46b2-d8cf-ce1716b3fe74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/160M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2be15b9a68ba4b2d977f95f5cd42f5ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        " train_set, batch_size=2, shuffle=True, num_workers=2,\n",
        " collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "xcJA6uSFpOcG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell for testing outputs\n",
        "images,targets = next(iter(dataloader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images,targets)\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)\n",
        "predictions"
      ],
      "metadata": {
        "id": "QAnyTfkdwyY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, scaler=None):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter(\"lr\", SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
        "    header = f\"Epoch: [{epoch}]\"\n",
        "\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1.0 / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "\n",
        "        lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "            optimizer, start_factor=warmup_factor, total_iters=warmup_iters\n",
        "        )\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # reduce losses over all GPUs for logging purposes\n",
        "        loss_dict_reduced = reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        loss_value = losses_reduced.item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(f\"Loss is {loss_value}, stopping training\")\n",
        "            print(loss_dict_reduced)\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if scaler is not None:\n",
        "            scaler.scale(losses).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    return metric_logger"
      ],
      "metadata": {
        "id": "OAb4anSSedLM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "vcIvcE3I2xeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train on the GPU or on the CPU, if a GPU is not available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# split the dataset in train and test set\n",
        "indices = torch.randperm(len(train_set)).tolist()\n",
        "dataset = torch.utils.data.Subset(train_set, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(test_set, indices[-50:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = dataloader\n",
        "\n",
        "#data_loader_test = torch.utils.data.DataLoader(\n",
        "#    dataset_test, batch_size=1, shuffle=False, num_workers=2,\n",
        "#    collate_fn=detection.utils.collate_fn)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                                momentum=0.9, weight_decay=0.0005)\n",
        "# and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                step_size=3,\n",
        "                                                gamma=0.1)\n",
        "\n",
        "# let's train it for 10 epochs\n",
        "num_epochs = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    #detection.engine.evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "torch.save(model.state_dict(), '/content/fasterrcnn2.h5')\n",
        "print(\"Training is over\")"
      ],
      "metadata": {
        "id": "mmS-T-Qt20TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f48682-2066-4928-f187-d447f6e492d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [0/5]  eta: 0:00:52  lr: 0.001254  loss: 0.8967 (0.8967)  loss_classifier: 0.7275 (0.7275)  loss_box_reg: 0.0015 (0.0015)  loss_objectness: 0.1641 (0.1641)  loss_rpn_box_reg: 0.0036 (0.0036)  time: 10.4301  data: 1.7274  max mem: 2363\n",
            "Epoch: [0]  [4/5]  eta: 0:00:02  lr: 0.005000  loss: 0.4492 (0.5088)  loss_classifier: 0.3175 (0.3696)  loss_box_reg: 0.0015 (0.0091)  loss_objectness: 0.1276 (0.1204)  loss_rpn_box_reg: 0.0049 (0.0097)  time: 2.5839  data: 0.3504  max mem: 3774\n",
            "Epoch: [0] Total time: 0:00:12 (2.5926 s / it)\n",
            "Epoch: [1]  [0/5]  eta: 0:00:03  lr: 0.005000  loss: 0.1568 (0.1568)  loss_classifier: 0.0929 (0.0929)  loss_box_reg: 0.0341 (0.0341)  loss_objectness: 0.0255 (0.0255)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 0.7538  data: 0.1494  max mem: 3774\n",
            "Epoch: [1]  [4/5]  eta: 0:00:00  lr: 0.005000  loss: 0.1801 (0.2517)  loss_classifier: 0.1014 (0.1516)  loss_box_reg: 0.0341 (0.0551)  loss_objectness: 0.0337 (0.0361)  loss_rpn_box_reg: 0.0058 (0.0088)  time: 0.6376  data: 0.0351  max mem: 3774\n",
            "Epoch: [1] Total time: 0:00:03 (0.6491 s / it)\n",
            "Epoch: [2]  [0/5]  eta: 0:00:05  lr: 0.005000  loss: 0.1639 (0.1639)  loss_classifier: 0.0746 (0.0746)  loss_box_reg: 0.0371 (0.0371)  loss_objectness: 0.0235 (0.0235)  loss_rpn_box_reg: 0.0287 (0.0287)  time: 1.0229  data: 0.2480  max mem: 3774\n",
            "Epoch: [2]  [4/5]  eta: 0:00:00  lr: 0.005000  loss: 0.2309 (0.2708)  loss_classifier: 0.0746 (0.1176)  loss_box_reg: 0.0708 (0.0838)  loss_objectness: 0.0562 (0.0614)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.6643  data: 0.0546  max mem: 3774\n",
            "Epoch: [2] Total time: 0:00:03 (0.6762 s / it)\n",
            "Epoch: [3]  [0/5]  eta: 0:00:04  lr: 0.000500  loss: 0.2259 (0.2259)  loss_classifier: 0.0764 (0.0764)  loss_box_reg: 0.0914 (0.0914)  loss_objectness: 0.0537 (0.0537)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 0.9419  data: 0.1782  max mem: 3774\n",
            "Epoch: [3]  [4/5]  eta: 0:00:00  lr: 0.000500  loss: 0.2115 (0.1995)  loss_classifier: 0.0686 (0.0668)  loss_box_reg: 0.0914 (0.0877)  loss_objectness: 0.0412 (0.0392)  loss_rpn_box_reg: 0.0035 (0.0059)  time: 0.6535  data: 0.0420  max mem: 3774\n",
            "Epoch: [3] Total time: 0:00:03 (0.6641 s / it)\n",
            "Epoch: [4]  [0/5]  eta: 0:00:04  lr: 0.000500  loss: 0.2257 (0.2257)  loss_classifier: 0.1032 (0.1032)  loss_box_reg: 0.0886 (0.0886)  loss_objectness: 0.0290 (0.0290)  loss_rpn_box_reg: 0.0049 (0.0049)  time: 0.9681  data: 0.1851  max mem: 3774\n",
            "Epoch: [4]  [4/5]  eta: 0:00:00  lr: 0.000500  loss: 0.2039 (0.2031)  loss_classifier: 0.0698 (0.0756)  loss_box_reg: 0.0886 (0.0945)  loss_objectness: 0.0290 (0.0283)  loss_rpn_box_reg: 0.0025 (0.0048)  time: 0.6583  data: 0.0429  max mem: 3774\n",
            "Epoch: [4] Total time: 0:00:03 (0.6711 s / it)\n",
            "Epoch: [5]  [0/5]  eta: 0:00:04  lr: 0.000500  loss: 0.1657 (0.1657)  loss_classifier: 0.0668 (0.0668)  loss_box_reg: 0.0691 (0.0691)  loss_objectness: 0.0258 (0.0258)  loss_rpn_box_reg: 0.0039 (0.0039)  time: 0.9750  data: 0.1862  max mem: 3774\n",
            "Epoch: [5]  [4/5]  eta: 0:00:00  lr: 0.000500  loss: 0.1657 (0.1730)  loss_classifier: 0.0668 (0.0627)  loss_box_reg: 0.0920 (0.0851)  loss_objectness: 0.0176 (0.0205)  loss_rpn_box_reg: 0.0028 (0.0047)  time: 0.6598  data: 0.0428  max mem: 3774\n",
            "Epoch: [5] Total time: 0:00:03 (0.6795 s / it)\n",
            "Epoch: [6]  [0/5]  eta: 0:00:04  lr: 0.000050  loss: 0.1734 (0.1734)  loss_classifier: 0.0573 (0.0573)  loss_box_reg: 0.0907 (0.0907)  loss_objectness: 0.0234 (0.0234)  loss_rpn_box_reg: 0.0019 (0.0019)  time: 0.8377  data: 0.2568  max mem: 3774\n",
            "Epoch: [6]  [4/5]  eta: 0:00:00  lr: 0.000050  loss: 0.1804 (0.1810)  loss_classifier: 0.0715 (0.0670)  loss_box_reg: 0.0907 (0.0908)  loss_objectness: 0.0190 (0.0184)  loss_rpn_box_reg: 0.0039 (0.0048)  time: 0.7030  data: 0.0607  max mem: 3887\n",
            "Epoch: [6] Total time: 0:00:03 (0.7141 s / it)\n",
            "Epoch: [7]  [0/5]  eta: 0:00:04  lr: 0.000050  loss: 0.1807 (0.1807)  loss_classifier: 0.0557 (0.0557)  loss_box_reg: 0.1121 (0.1121)  loss_objectness: 0.0106 (0.0106)  loss_rpn_box_reg: 0.0023 (0.0023)  time: 0.8903  data: 0.3104  max mem: 3887\n",
            "Epoch: [7]  [4/5]  eta: 0:00:00  lr: 0.000050  loss: 0.1807 (0.1825)  loss_classifier: 0.0611 (0.0609)  loss_box_reg: 0.0954 (0.1006)  loss_objectness: 0.0165 (0.0163)  loss_rpn_box_reg: 0.0025 (0.0047)  time: 0.6976  data: 0.0676  max mem: 3887\n",
            "Epoch: [7] Total time: 0:00:03 (0.7298 s / it)\n",
            "Training is over\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2aKCNYgiKCj",
        "outputId": "4d9081f5-ce04-4194-c474-053440be9acc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = get_transform(train=False)"
      ],
      "metadata": {
        "id": "ZT5I3vl6l1lI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/1.jpeg').convert(\"RGB\")\n",
        "img = transform(img)\n",
        "img = img.cuda()\n",
        "model.eval()\n",
        "prediction = model((img,))\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aol6u5vuiR9X",
        "outputId": "d71af139-faa2-4ecb-87b1-3d687d8a725c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'boxes': tensor([[239.8196, 440.7705, 339.3933, 539.4921],\n",
              "          [166.4177, 439.4568, 386.4370, 544.6243],\n",
              "          [197.6655, 440.0789, 296.4489, 540.0864],\n",
              "          [242.7691, 447.7349, 381.3595, 512.0982],\n",
              "          [219.7668, 454.1010, 318.7171, 563.2122],\n",
              "          [278.4780, 431.9431, 343.4335, 567.3729],\n",
              "          [210.3877, 437.1707, 348.8278, 502.6105],\n",
              "          [188.0201, 465.8103, 283.3354, 576.2057],\n",
              "          [240.8364, 377.2519, 342.1846, 608.4230],\n",
              "          [257.0763, 405.6508, 320.1521, 536.2310],\n",
              "          [191.6536, 378.7079, 294.7998, 609.5652],\n",
              "          [235.2463, 406.9960, 298.0741, 536.4868],\n",
              "          [192.0762, 420.9538, 254.2723, 544.6440],\n",
              "          [197.6287, 506.1664, 293.4708, 607.8303],\n",
              "          [285.6390, 534.9506, 425.8648, 599.7220],\n",
              "          [ 73.9169, 113.6971, 169.7932, 218.6502],\n",
              "          [307.6358, 448.8411, 408.0442, 549.4703],\n",
              "          [114.0092,  83.5613, 174.4879, 221.2652],\n",
              "          [288.0507, 156.0025, 423.5787, 222.5877],\n",
              "          [184.0544, 448.9502, 241.8555, 590.9499],\n",
              "          [126.6310,  51.2995, 184.6999, 190.5213],\n",
              "          [147.3116,  82.3254, 207.8894, 220.9131]], device='cuda:0',\n",
              "         grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         device='cuda:0'),\n",
              "  'scores': tensor([0.2885, 0.2684, 0.2612, 0.2051, 0.2045, 0.2001, 0.1863, 0.1406, 0.1395,\n",
              "          0.1383, 0.1354, 0.1301, 0.1206, 0.1132, 0.1128, 0.0876, 0.0839, 0.0835,\n",
              "          0.0791, 0.0772, 0.0724, 0.0550], device='cuda:0',\n",
              "         grad_fn=<IndexBackward0>)}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.core import keypoint_ops\n",
        "from object_detection.core import standard_fields as fields\n",
        "from object_detection.utils import shape_utils\n"
      ],
      "metadata": {
        "id": "O6LXWJdrnHqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "box_tensor = prediction[0][\"boxes\"][i]\n",
        "caption = label(prediction[0][\"labels\"][i].item())\n",
        "score = str(round(prediction[0][\"scores\"][i].item(), 2))\n",
        "vis_utils.draw_bounding_box_on_image(image=img, xmin=box_tensor[0].item(), ymin=box_tensor[1].item(),\n",
        "                                             xmax=box_tensor[2].item(),\n",
        "                                             ymax=box_tensor[3].item(), use_normalized_coordinates=False,\n",
        "                                             display_str_list=[caption, score], thickness=3)\n",
        "\n",
        "img_name = ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits))\n",
        "img.save(os.path.join('/content/', img_name))\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "yfP4yh1smG-H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}